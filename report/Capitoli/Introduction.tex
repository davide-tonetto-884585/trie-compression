\chapter{Introduction} \label{chp:introduction}
\section{Project Overview}
The increasing availability of large, structured datasets, such as those found in XML documents, biological data, and hierarchical knowledge bases, has led to the need for efficient compression techniques for trees.
Trees are a natural choice for representing hierarchical data due to their ability to model parent-child relationships and nested structures. For instance, an XML document is inherently a tree, where tags are nested to create a structured hierarchy. Similarly, file systems are organized as trees of directories and files, and biological data, such as phylogenetic trees, use this structure to represent evolutionary relationships. Given their ubiquity in representing complex data, developing effective compression methods for trees is of paramount importance.
Traditional compression methods, such as general-purpose text compression algorithms, often fail to effectively exploit the hierarchical structure of trees. Consequently, specialized tree compression techniques have been developed to address this issue.

Among the most prominent techniques for tree compression, the \textit{Extended Burrows-Wheeler Transform} \cite{ferragina2009compressing} extends the classical Burrows-Wheeler Transform to labeled trees, leveraging their structural properties to achieve significant compression. Another notable approach includes \textit{Re-Pair-based compression} \cite{lohrey2011tree}, which applies grammar-based compression to the tree structure. 

Despite these advancements, existing techniques may not be optimal when dealing with trees characterized by a high degree of repetitiveness. Many real-world datasets, such as versioned documents or biological phylogenies, contain repeated substructures that can be exploited to achieve better compression. This thesis aims to study a novel compression technique designed to efficiently handle such highly repetitive trees. We implement and evaluate this method, comparing it with existing state of the art approaches to determine its effectiveness in different scenarios.

\section{Background and State of The Art} \label{sec:background}
Before the advent of the XBWT, Kosaraju \cite{kosaraju1989efficient} proposed a method to index labeled trees by extending the concept of prefix sorting, which is commonly applied to strings, to work with labeled trees by leveraging the structure of tries (prefix trees). To achieve this, he introduced the idea of constructing a suffix tree for a reversed trie allowing subpath queries in $O(|P|\log|\Sigma|+ occ)$ time, where $occ$ is the number of occurrences of $P$ in $T$ but still requiring $O(t \log t)$ space and so not being compressed.

The Extended Burrows-Wheeler Transform (XBWT) \cite{ferragina2009compressing} is a data structure designed for efficient compression and indexing of ordered node-labeled trees.
The XBWT works by linearizing a labeled tree into two arrays: one captures the structural properties of the tree, and the other stores its labels. This transformation allows for efficient representation, navigation, and querying of the tree. The key advantage of the XBWT lies in its ability to compress labeled trees while supporting a wide range of operations, such as parent-child navigation and sophisticated path-based searches, in (near-)optimal time and space.
The XBWT provides significant improvements in both compression ratio and query performance compared to traditional compression schemes, making it a valid resource for intensive applications.

Another notable approach is Tree Re-Pair \cite{lohrey2011tree}, a grammar-based compression technique adapted for tree structures. It extends the principles of the original Re-Pair algorithm \cite{larsson2000off} to handle the hierarchical nature of trees by identifying and compactly representing frequently occurring patterns.
The core idea of the tool is to identify frequently occurring patterns within the tree and represent them more compactly.
The process involves the linearization of the tree (e.g., using a specific traversal order) and then the application of the Re-Pair logic. In this way, it finds the most frequent pair of adjacent elements (which could represent nodes, labels, or structural components, depending on the linearization) in the sequence. The pair is then replaced by a new non-terminal symbol, and the corresponding production rule is added to a grammar. All this process is then repeated until no more pairs occur frequently enough or some other stopping criterion is met. The final output is a relatively small grammar (a set of production rules) and a sequence of symbols (including the newly introduced non-terminals) that can be used to reconstruct the original tree. An application of Tree Re-Pair to XML documents can be found in \cite{lohrey2013xml}.
While Tree Re-Pair is effective for general tree compression, this thesis focuses on developing a novel technique specifically tailored for highly repetitive trees. Therefore, we use the XBWT as our primary benchmark for comparison, as it represents a well-established and high-performance baseline in the field.

\section{Challenges and Contributions}
In order to develop an effective tree compression scheme that can exploit repetitive structures, we need to address several key challenges:
\begin{itemize}
    \item \textbf{Identification of repetitive structures:} The first step in compressing repetitive trees is to identify the repeated substructures efficiently. This requires the development of algorithms capable of detecting and representing these structures compactly.
    \item \textbf{Optimization of representation:} Once the repetitive structures have been identified, the challenge is to represent them in an optimized way that minimizes the overall size of the compressed tree. This involves finding the most efficient encoding for the repeated substructures.
\end{itemize}

We address these challenges by developing a novel tree compression scheme that first leverages the well-known automata minimization algorithm to identify repetitive structures. This algorithm efficiently groups together similar subtrees, enabling us to identify and compress them with high efficiency. The tree is treated as a deterministic finite automaton (DFA) where the root is the initial state and the leaves are the final states. Since trees are acyclic graphs, this structure is a specific type of DFA known as a Directed Acyclic Word Graph (DAWG). For this reason, we focus on an adaptation of Revuz's algorithm, which is specifically designed for minimizing acyclic DFAs, to make it more efficient for our purposes.

Then, we optimize the representation of these structures. Our approach is to partition the tree nodes into chains and apply Run-Length Encoding (RLE), a compression technique that stores sequences of identical data as a single value and a count. The key challenge is to create partitions that maximize the effectiveness of RLE. We prove that this optimization problem can be reduced to the Minimum Weight Perfect Bipartite Matching (MWPBM) problem. MWPBM is a classic graph theory problem focused on finding a pairing of all nodes in a bipartite graph such that the sum of the weights of the connecting edges is minimized. By modeling our partitioning problem as a bipartite graph, we can use efficient algorithms for MWPBM to find the optimal representation and achieve a higher compression ratio.

\section{Structure of The Thesis}
This thesis is structured to guide the reader from the foundational concepts of tree compression to the development and evaluation of our novel approach. The goal is to build a clear understanding of why each component of our proposed pipeline is necessary and how they fit together.

The logical flow is as follows:
\begin{itemize}
    \item We begin in \textbf{\cref{chp:thbg_labeled_tree}} by establishing the necessary theoretical background on labeled trees.
    \item In \textbf{\cref{chp:tree_compression}}, we examine the Extended Burrows-Wheeler Transform (XBWT), a state-of-the-art tree compression technique. This serves as a benchmark and highlights the opportunity for improvement, particularly in handling highly repetitive structures.
    \item To address this, we introduce a new approach based on automata. \textbf{\cref{chp:hopcroft}} describes how we use Deterministic Finite Automata (DFA) to model the tree's structure and apply Hopcroft's algorithm to minimize this automaton, effectively identifying all unique subtrees (i.e., the repetitions).
    \item Once repetitions are identified, we need an efficient way to store them. \textbf{\cref{chp:min_weight_perfect_bipartite_matching}} introduces the Minimum Weight Perfect Bipartite Matching problem, which we use to find an optimal way to chain the identified repetitive structures, minimizing the overall compressed size.
    \item \textbf{\cref{chp:project_overview}} unites these concepts, presenting the complete pipeline of our proposed compression scheme.
    \item Finally, \textbf{\cref{chp:implementation,chp:experimental_results,chp:conclusions}} describe the implementation, present the experimental results of our method against the benchmark, and discuss our conclusions and future work.
\end{itemize}
