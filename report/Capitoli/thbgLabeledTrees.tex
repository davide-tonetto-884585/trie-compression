\section{Labeled Trees and Tries} \label{chp:thbg_labeled_tree}
In this chapter, we will discuss labeled trees, a fundamental data structure used to represent hierarchical data. We will define the concept of a labeled tree, explore its common applications, and introduce the core concepts behind its compression and indexing.

\subsection{Introduction and Motivation}
Before delving into specific compression techniques, it is essential to establish a solid theoretical foundation regarding labeled trees and tries. These structures are fundamental for representing hierarchical data across diverse fields, from bioinformatics to document processing. This chapter provides the necessary background, defining labeled trees, exploring their common applications, and introducing the core concepts behind their compression and indexing. 

While labeled trees encompass a broad class of hierarchical structures, this thesis focuses specifically on tries. This focus is motivated by our compression strategy, which relies on identifying and merging identical subtrees. To formally identify these subtrees, we compute the Myhill-Nerode equivalence classes of the trie's states (see \cref{def:myhill-nerode}), a task that can be accomplished using algorithms for DFA minimization. A fundamental prerequisite for these algorithms is determinism, as they require that from any given state, each symbol corresponds to at most one transition. Tries inherently provide this guarantee, since from any node, there is at most one outgoing edge for each symbol in the alphabet. This deterministic nature is therefore what allows us to apply powerful automata minimization techniques to compress the tree structure. 

\subsection{Applications}
Labeled trees are widely used in computer science and data representation due to their hierarchical structure and flexibility in modeling relationships. Prominent applications include:
\begin{enumerate}
    \item \textbf{XML Data Representation:} XML documents are often modeled as labeled trees, where each element is a node labeled by its tag, and hierarchical nesting represents parent-child relationships.
    \item \textbf{JSON Data Representation:} JSON documents can be viewed as labeled trees, with keys as labels and values as children.
    \item \textbf{Bioinformatics:} Labeled trees are used to represent phylogenetic trees, genome annotations, and hierarchical clustering.
    \item \textbf{Compiler Design:} Abstract Syntax Trees (ASTs) for programming languages are labeled trees that capture the structure of code.
    \item \textbf{File Systems:} The directory structure of file systems can be viewed as a labeled tree.
\end{enumerate}

Efficient representation, navigation, and querying of labeled trees are essential for many applications, motivating the development of specialized data structures and algorithms. 

\subsection{Indexing} \label{compandindexinglabtree}
The goal of compressing and indexing labeled trees is to design a compressed storage scheme for a labeled tree $T$ with $t$ nodes that allows for efficient navigation operations in $T$, as well as fast search and retrieval of subtrees or paths within $T$. To be effective, the compressed representation should minimize the space required to store the tree while supporting a wide range of operations in optimal ($O(1)$) or (near-)optimal time.

We define the following navigation operations on $T$:
\begin{definition}[Tree Operations] \label{def:tree_operations}
Let $T$ be a labeled tree with node set $V$, $u \in V$ be a node, and $c \in \Sigma$ be a symbol. We define the following fundamental operations on $T$:

\begin{itemize}
    \item \textbf{Navigational queries:} ask for the parent of $u$, the $i$-th child of $u$, or the label of $u$. The last two operations might be restricted to the children of $u$ with a specific label $c$.
    \item \textbf{Visualization queries:} retrieve the nodes in the subtree rooted at $u$ (any possible order should be implemented).
    \item \textbf{Subpath queries:} Let moreover $P(\alpha)$ be the set of vertices of $N$ which are reached by a path labeled with a given word $\alpha \in \Sigma^*$. Efficient subpath queries that, given a query word $\alpha \in \Sigma^*$, solve:
    \begin{itemize}
        \item Existential queries: Determine whether $P(\alpha) \neq \emptyset$, i.e., whether $\alpha$ matches a substring of some string in the language of $T$.
        \item Count queries: Compute the cardinality of $P(\alpha)$.
        \item Locate queries: Return a representation for all the vertices in $P(\alpha)$.
    \end{itemize}
\end{itemize}
\end{definition}

A naive solution to index labeled trees is to store the tree as a list of nodes with their labels and parent-child relationships using pointers in $O(t \log t)$. However, this representation is not space-efficient and does not support fast navigation or query operations. 

Many data structures have been proposed to compress and index labeled trees, each with its trade-offs in terms of space usage, query performance, and supported operations. One of the most successful approaches is the Extended Burrows-Wheeler Transform, which extends the classical Burrows-Wheeler Transform (BWT) to handle labeled trees efficiently (\cref{sec:background}).

\begin{comment}
    \section{Succinct Data Structures for Trees}
    \alessio{Questa sezione non Ã¨ ben collegata al resto. Serve questa parentesi sulle SDS? Dato che anche prima parli di minimizzare lo spazio e time optimality, potresti parlare direttamente dei lower bound. Il filo logico sarebbe: "vogliamo fare le cose il meglio possibile, ma quanto vale il meglio?"}
    In order to compress the index of labeled trees, we need to avoid the use of pointers and store the tree in a space-efficient manner. Succinct data structures are a class of compressed data structures that support efficient navigation and query operations on the compressed data. These structures are designed to use close to the information-theoretic lower bound on space while providing fast access to the original data. They were first introduced by Jacobson \cite{jacobson1989space} and have been applied to various problems in string processing, graph theory, and data compression.
\end{comment}

\subsection{Information-Theoretic Lower Bound}
Before computing the information-theoretic lower bound for labeled trees, it is essential to define the concept of worst-case entropy, which provides a formal measure of the minimum number of bits required to represent any object from a given set. As detailed by Navarro \cite{navarro2016compact}, this is a fundamental concept in data structure design.

\begin{definition}[Worst-case entropy]
Let $U$ be a universe of combinatorial objects. The worst-case entropy of $U$ is 
$$ H_{wc}(|U|) = \lceil\log_2(|U|)\rceil $$
\end{definition}

This definition establishes that the minimum number of bits to uniquely identify any object in a set $U$ is the logarithm of the size of $U$, rounded up to the nearest integer. We now apply this principle to determine the lower bound for labeled trees.

\begin{lemma} \label{lem:info_theoretic_lower_bound}
The information-theoretic lower bound for storing a labeled tree $T$ with $t$ nodes over an alphabet $\Sigma$ is $2t + t \log_2 |\Sigma| - \Theta(\log t)$ bits.
\end{lemma}

\begin{proof}
The total information required to store a labeled tree can be decomposed into two components: the space needed to encode the tree's structure and the space needed to encode the labels on its nodes.

\textbf{1. Structural Information (Unlabeled Tree):}
The number of distinct unlabeled binary trees with $t$ nodes is given by the $t$-th Catalan number, $C_t = \frac{1}{t+1} \binom{2t}{t}$. Using Stirling's approximation for factorials, the Catalan number can be approximated as:
$$C_t \approx \frac{4^t}{t^{3/2}\sqrt{\pi}}$$
Then, the worst-case entropy (or the information-theoretic minimum number of bits to encode
the structure of the tree) is:
$$\log_2 C_t \approx \log_2\left(\frac{4^t}{t^{3/2}\sqrt{\pi}}\right) = \log_2(4^t) - \log_2(t^{3/2}\sqrt{\pi}) = 2t - \frac{3}{2}\log_2 t - \frac{1}{2}\log_2 \pi$$
The lower-order terms can be expressed using Big Theta notation as $\Theta(\log t)$. Therefore, the space required for the structure is $2t - \Theta(\log t)$ bits.

\textbf{2. Labeling Information:}
For a tree with $t$ nodes and an alphabet $\Sigma$, each node must be assigned a label. To distinguish between $|\Sigma|$ possible labels, a minimum of $\log_2 |\Sigma|$ bits is required for each node. Consequently, the total space required to store the labels for all $t$ nodes is:
$$t \log_2 |\Sigma| \text{ bits}$$

Finally, by adding the space required for the structure and the labels, the total information-theoretic lower bound for storing a labeled tree is the sum of the two components:
$$ (2t - \Theta(\log t)) + (t \log_2 |\Sigma|) = 2t + t \log_2 |\Sigma| - \Theta(\log t) \text{ bits} $$
This completes the proof.
\end{proof}


\subsection{State of The Art} \label{sec:background}
The field of tree indexing and compression has evolved through two main paradigms: succinct data structures that achieve space-optimal representations, and compression techniques that exploit structural repetitions.

In the realm of succinct tree structures, early work by Kosaraju \cite{kosaraju1989efficient} proposed a method to index labeled trees by extending the concept of prefix sorting from strings to labeled trees using trie structures. He introduced the idea of constructing a suffix tree for a reversed trie, enabling subpath queries in $O(|P|\log|\Sigma|+ occ)$ time, where $occ$ is the number of occurrences of $P$ in $T$. However, this approach still required $O(t \log t)$ space (where $t$ is the number of nodes of the tree) and thus was not compressed.

A significant advancement in this direction came with the Extended Burrows-Wheeler Transform (XBWT) \cite{ferragina2009compressing}, a data structure designed for efficient compression and indexing of ordered node-labeled trees. The XBWT works by linearizing a labeled tree into two arrays capturing the structural properties of the tree and its labels. This transformation allows for efficient representation, navigation, and querying of the tree. The key advantage of the XBWT lies in its ability to compress labeled trees while supporting a wide range of operations, such as navigation, visualization and subpath queries (see \cref{def:tree_operations}), within (near-)optimal time bounds and entropy-bounded space. The XBWT provides significant improvements in both compression ratio and query performance compared to traditional compression schemes, making it a valuable resource for intensive applications.

Complementing succinct approaches, tree compression has been extensively studied through different paradigms that exploit structural repetitions in distinct ways. One of the classical approaches is \emph{DAG compression}, which represents a tree as a minimal directed acyclic graph (DAG) by identifying and merging identical rooted subtrees. Concretely, whenever two identical subtrees occur, only one copy is stored and all occurrences point to it. The resulting structure can be exponentially smaller than the original tree and can be computed in linear time. DAG compression has been widely used in programming languages, binary decision diagrams, and XML representations \cite{billeTreeCompressionTop2015}.

Another line of research extends the well-known LZ77 factorisation from strings to trees. Here, the tree is decomposed into edge-disjoint fragments, each being either a single node or a copy of a fragment that appeared earlier in a breadth-first traversal. Each fragment is thus defined by pointers to earlier occurrences, much like in the string version of LZ77. This factorisation uniquely determines the tree, and by minimising the number of fragments one obtains a compressed representation. Importantly, such factorizations can be computed in polynomial time (and in linear time for restricted variants), and they yield representations no larger than the smallest tree grammar, thus bridging block compression and grammar-based compression \cite{gawrychowskiLZ77FactorisationTrees2016}.

More recently, top tree compression has been proposed as a method that combines the advantages of subtree sharing and grammar-like approaches. The key idea is to build a hierarchical top tree decomposition, where the input tree is recursively partitioned into clusters that capture connected patterns. These clusters are then merged following a restricted set of operations, producing a binary decomposition tree whose internal repetitions are turned into subtree repeats. Finally, this decomposition is compressed using standard DAG compression, resulting in a so-called top DAG. This approach achieves close-to-optimal worst-case bounds, can be exponentially more succinct than DAG compression, and crucially, supports a wide range of navigational queries (e.g., parent, child, depth, nearest common ancestor) in logarithmic time directly on the compressed representation \cite{billeTreeCompressionTop2015}.

Another notable approach is Tree Re-Pair \cite{lohrey2011tree}, a grammar-based compression technique adapted for tree structures. It extends the principles of the original Re-Pair algorithm \cite{larsson2000off} to handle the hierarchical nature of trees by identifying and compactly representing frequently occurring patterns.
The core idea of the tool is to identify frequently occurring patterns within the tree and represent them more compactly.
The process involves the linearization of the tree (e.g., using a specific traversal order) and then the application of the Re-Pair logic. In this way, it finds the most frequent pair of adjacent elements (which could represent nodes, labels, or structural components, depending on the linearization) in the sequence. The pair is then replaced by a new non-terminal symbol, and the corresponding production rule is added to a grammar. All this process is then repeated until no more pairs occur frequently enough or some other stopping criterion is met. The final output is a relatively small grammar (a set of production rules) and a sequence of symbols (including the newly introduced non-terminals) that can be used to reconstruct the original tree. An application of Tree Re-Pair to XML documents can be found in \cite{lohrey2013xml}.

In summary, DAG compression is efficient but limited to subtree repeats, LZ77 factorisation captures more general repetitions while relating closely to grammar-based methods such as Tree Re-Pair, and top tree compression strikes a balance by exploiting both subtree and pattern repeats while still enabling efficient query support.

This thesis focuses on developing a novel technique specifically tailored for highly repetitive tries. Our approach leverages the structural properties unique to tries and their repetitive patterns. Therefore, we use the XBWT as our primary benchmark for comparison, as it represents a well-established and high-performance baseline specifically designed for trie compression in the field.

\subsection{Conclusion}
This section has established the initial theoretical groundwork for the thesis, beginning with the formal definition of labeled trees and narrowing the focus to tries. We have underscored the deterministic nature of tries as a critical property that makes them suitable for DAG compression techniques. Furthermore, we defined a standard set of navigational and query operations, providing a benchmark for the functionality that an efficient compressed structure must support. By establishing the information-theoretic lower bound for storing labeled trees, we have set a clear goal for compression effectiveness.

The primary objective of this thesis is to develop and analyze a novel approach that leverages DAG compression to reduce the space footprint of tries, particularly those with highly repetitive substructures. Crucially, our goal is not merely to compress but to do so while preserving the trie's indexability. The subsequent chapters will detail the methods for achieving this, aiming to create a compressed representation that approaches the theoretical space limits while supporting essential query operations efficiently.

In the next section, we present a detailed explanation of the Extended Burrows-Wheeler Transform (XBWT), examining its construction, properties, and how it enables efficient compression and indexing of labeled trees.

