\chapter{Novel Tree Compression Scheme Focused on Repetitive Structures} \label{chp:project_overview}
As introduced in the first chapter of this thesis, the main goal of this work is to develop a new tree compression scheme that is able to exploit the presence of repetitive structures in the input tree. The idea is to design a compression algorithm that is able to identify and compress the repetitive parts of the input tree, while still being able to represent the non-repetitive parts of the tree in a compact way. The main motivation behind this work is to improve the compression performance of tree compression algorithms when dealing with trees that contain repetitive structures. In this chapter, we provide an overview of the proposed tree compression scheme.

\section{The novel compression scheme pipeline}
Let $ T $ be an ordered tree of arbitrary fan-out, depth, and shape. $ T $ consists of $ n $ internal nodes and $ \ell $ leaves, for a total of $ t = n + \ell $ nodes. Every node of $ T $ is labeled with a symbol drawn from an alphabet $ \Sigma $. We assume that $ \Sigma $ is the set of labels effectively used in the nodes of $T$ and that these labels are encoded with the integers in the range $[1, |\Sigma|]$. Then we need to define the array $\pi$ where, for each node $u$, $\pi(u)$ is the string obtained by concatenating the labels on the \textbf{upward path} from the parent of $u$ to the root of the tree (root has an empty $\pi$ component).

The following pipeline is used to compress the tree $T$:
\begin{enumerate}
    \item Initially the array $\pi$ is computed for the tree $T$ by traversing the tree in a pre-order fashion. Then the nodes are stably sorted by the lexicographic order of their $\pi$ strings. In order to sort the nodes, the \textbf{Path Sort} algorithm introduced in \cite{ferragina2009compressing} is used, allowing to sort nodes in linear time and $O(t \log t)$ space. An implementation of this algorithm in C++ is available in the author's GitHub in the following repository: \url{https://github.com/davide-tonetto-884585/XBWT}.
    \item Then, using a variant of the Hopcroft algorithm for minimization of DFA \cite{HOPCROFT1971189} that works over directed acyclic graphs \cite{revuz1992minimisation} and so over trees, the nodes are partitioned into equivalence classes where two nodes are equivalent (has the same class) if they have the same subtree rooted at them.
    \item Given a width $p$, the nodes previously sorted are then divided into $p$ chains with the aim of minimizing the run-length encoding of each chain (by considering the equivalence classes). In order to do so we reduced this problem (\textsc{CHAINS-DIVISION} problem) to the Minimum Perfect Bipartite Matching problem, which can be solved in polynomial time as introduced in \cite{chen2022maximum} and \cite{sankowski2009maximum}.
    \item Lastly, the resulting deterministic finite automaton (DFA) or non-deterministic finite automaton (NFA) can be indexed using the indexing scheme introduced by Cotumaccio et al. \cite{cotumaccio2023co}. Also, the chains may be compressed using some techniques such as run-length encoding, Huffman encoding, and Elias-Fano encoding.
\end{enumerate}